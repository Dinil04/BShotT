{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743655359.605915  447240 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1743655359.692999  447441 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743655359.707091  447438 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "pose = mp.solutions.pose.Pose()\n",
    "dataset_path = \"cricket_shot\"\n",
    "output_path = \"cricket_shot_angles\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Helper\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    return 360 - angle if angle > 180 else angle\n",
    "\n",
    "def extract_landmark(lm, name):\n",
    "    return [lm[mp.solutions.pose.PoseLandmark[name].value].x,\n",
    "            lm[mp.solutions.pose.PoseLandmark[name].value].y]\n",
    "\n",
    "# Process each video\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(\".mp4\") or filename.endswith(\".MOV\"):\n",
    "        video_path = os.path.join(dataset_path, filename)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        angles = []\n",
    "        frame_num = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (640, 360))\n",
    "            results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            frame_num += 1\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                lm = results.pose_landmarks.landmark\n",
    "                try:\n",
    "                    rs = extract_landmark(lm, \"RIGHT_SHOULDER\")\n",
    "                    re = extract_landmark(lm, \"RIGHT_ELBOW\")\n",
    "                    rw = extract_landmark(lm, \"RIGHT_WRIST\")\n",
    "                    rh = extract_landmark(lm, \"RIGHT_HIP\")\n",
    "                    rk = extract_landmark(lm, \"RIGHT_KNEE\")\n",
    "                    ra = extract_landmark(lm, \"RIGHT_ANKLE\")\n",
    "                    le = extract_landmark(lm, \"LEFT_EYE\")\n",
    "                    no = extract_landmark(lm, \"NOSE\")\n",
    "                    reye = extract_landmark(lm, \"RIGHT_EYE\")\n",
    "\n",
    "                    angles.append({\n",
    "                        \"frame\": frame_num,\n",
    "                        \"elbow\": calculate_angle(rs, re, rw),\n",
    "                        \"shoulder\": calculate_angle(rh, rs, re),\n",
    "                        \"knee\": calculate_angle(rh, rk, ra),\n",
    "                        \"body\": calculate_angle(rs, rh, rk),\n",
    "                        \"face\": calculate_angle(le, no, reye)\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Save angles\n",
    "        shot_name = os.path.splitext(filename)[0]\n",
    "        df = pd.DataFrame(angles)\n",
    "        df.to_csv(os.path.join(output_path, f\"{shot_name}_angles.csv\"), index=False)\n",
    "\n",
    "        # Optional: print angle range summary\n",
    "        if not df.empty:\n",
    "            summary = {\n",
    "                \"elbow\": (round(df[\"elbow\"].min(), 1), round(df[\"elbow\"].max(), 1)),\n",
    "                \"shoulder\": (round(df[\"shoulder\"].min(), 1), round(df[\"shoulder\"].max(), 1)),\n",
    "                \"knee\": (round(df[\"knee\"].min(), 1), round(df[\"knee\"].max(), 1)),\n",
    "                \"body\": (round(df[\"body\"].min(), 1), round(df[\"body\"].max(), 1)),\n",
    "                \"face\": (round(df[\"face\"].min(), 1), round(df[\"face\"].max(), 1)),\n",
    "            }\n",
    "            print(f\"{shot_name} ➤ {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743655813.129532  447240 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n",
      "W0000 00:00:1743655813.203860  453713 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743655813.225830  453713 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cricket_shot/Defence/IMG_2457.MOV\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m frame_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m---> 38\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup paths\n",
    "dataset_path = \"cricket_shot\"\n",
    "output_path = \"cricket_shot_angles\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Initialize pose detector\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Angle calculation helper\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    return 360 - angle if angle > 180 else angle\n",
    "\n",
    "# Landmark extractor\n",
    "def get_lm(lm, name):\n",
    "    return [lm[mp_pose.PoseLandmark[name].value].x, lm[mp_pose.PoseLandmark[name].value].y]\n",
    "\n",
    "# Loop through all subfolders and videos\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".mp4\", \".mov\")):\n",
    "            video_path = os.path.join(root, file)\n",
    "            print(f\"Processing {video_path}\")\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            angles = []\n",
    "            frame_count = 0\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, (640, 360))\n",
    "                results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                frame_count += 1\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    lm = results.pose_landmarks.landmark\n",
    "                    try:\n",
    "                        rs = get_lm(lm, \"RIGHT_SHOULDER\")\n",
    "                        re = get_lm(lm, \"RIGHT_ELBOW\")\n",
    "                        rw = get_lm(lm, \"RIGHT_WRIST\")\n",
    "                        rh = get_lm(lm, \"RIGHT_HIP\")\n",
    "                        rk = get_lm(lm, \"RIGHT_KNEE\")\n",
    "                        ra = get_lm(lm, \"RIGHT_ANKLE\")\n",
    "                        le = get_lm(lm, \"LEFT_EYE\")\n",
    "                        no = get_lm(lm, \"NOSE\")\n",
    "                        reye = get_lm(lm, \"RIGHT_EYE\")\n",
    "\n",
    "                        angles.append({\n",
    "                            \"frame\": frame_count,\n",
    "                            \"elbow\": calculate_angle(rs, re, rw),\n",
    "                            \"shoulder\": calculate_angle(rh, rs, re),\n",
    "                            \"knee\": calculate_angle(rh, rk, ra),\n",
    "                            \"body\": calculate_angle(rs, rh, rk),\n",
    "                            \"face\": calculate_angle(le, no, reye)\n",
    "                        })\n",
    "                    except:\n",
    "                        continue\n",
    "            cap.release()\n",
    "\n",
    "            # Save angles\n",
    "            if angles:\n",
    "                label = os.path.basename(root)  # e.g., 'Cover_Drive'\n",
    "                base_name = os.path.splitext(file)[0]  # e.g., 'video1'\n",
    "                df = pd.DataFrame(angles)\n",
    "                save_path = os.path.join(output_path, f\"{label}_{base_name}_angles.csv\")\n",
    "                df.to_csv(save_path, index=False)\n",
    "                print(f\"Saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743655859.495341  447240 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n",
      "W0000 00:00:1743655859.599909  454256 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743655859.619987  454256 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📽️ Processing: cricket_shot/Defence/IMG_2457.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2457_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2443.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2443_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2442.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2442_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2456.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2456_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2468.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2468_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2440.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2440_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2454.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2454_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2455.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2455_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2441.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2441_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2469.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2469_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2451.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2451_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2450.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2450_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2444.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2444_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2452.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2452_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2446.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2446_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2447.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2447_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2453.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2453_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2434.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2434_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2435.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2435_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2437.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2437_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2436.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2436_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2432.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2432_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2433.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2433_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2438.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2438_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2439.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2439_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2462.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2462_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2463.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2463_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2449.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2449_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2461.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2461_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2474.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2474_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2460.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2460_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2448.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2448_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2464.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2464_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2470.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2470_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2458.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2458_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2459.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2459_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2471.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2471_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2465.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2465_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2473.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2473_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2467.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2467_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2466.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2466_angles.csv\n",
      "📽️ Processing: cricket_shot/Defence/IMG_2472.MOV\n",
      "✅ Saved: cricket_shot_angles/Defence/IMG_2472_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2523.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2523_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2537.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2537_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2536.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2536_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2522.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2522_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2534.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2534_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2535.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2535_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2531.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2531_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2525.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2525_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2524.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2524_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2530.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2530_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2526.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2526_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2532.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2532_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2533.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2533_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2527.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2527_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2540.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2540_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2554.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2554_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2555.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2555_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2541.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2541_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2557.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2557_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2543.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2543_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2542.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2542_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2556.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2556_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2552.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2552_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2546.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2546_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2547.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2547_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2553.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2553_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2545.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2545_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2551.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2551_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2550.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2550_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2544.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2544_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2549.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2549_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2561.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2561_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2560.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2560_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2548.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2548_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2562.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2562_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2558.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2558_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2559.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2559_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2529.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2529_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2528.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2528_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2538.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2538_angles.csv\n",
      "📽️ Processing: cricket_shot/Cut_shot/IMG_2539.MOV\n",
      "✅ Saved: cricket_shot_angles/Cut_shot/IMG_2539_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2391.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2391_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2385.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2385_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2420.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2420_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2421.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2421_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2409.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2409_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2384.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2384_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2390.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2390_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2386.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2386_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2392.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2392_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2423.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2423_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2393.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2393_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2387.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2387_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2383.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2383_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2397.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2397_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2426.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2426_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2427.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2427_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2396.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2396_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2394.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2394_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2431.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2431_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2425.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2425_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2419.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2419_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2418.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2418_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2424.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2424_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2430.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2430_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2381.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2381_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2395.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2395_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2398.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2398_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2429.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2429_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2415.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2415_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2401.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2401_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2400.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2400_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2414.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2414_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2428.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2428_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2399.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2399_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2402.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2402_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2416.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2416_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2417.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2417_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2403.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2403_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2407.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2407_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2413.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2413_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2412.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2412_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2406.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2406_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2389.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2389_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2410.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2410_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2405.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2405_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2411.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2411_angles.csv\n",
      "📽️ Processing: cricket_shot/Cover_Drive/IMG_2388.MOV\n",
      "✅ Saved: cricket_shot_angles/Cover_Drive/IMG_2388_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2480.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2480_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2481.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2481_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2495.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2495_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2483.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2483_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2497.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2497_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2508.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2508_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2520.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2520_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2521.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2521_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2509.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2509_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2496.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2496_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2482.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2482_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2486.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2486_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2479.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2479_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2519.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2519_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2518.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2518_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2478.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2478_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2487.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2487_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2491.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2491_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2485.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2485_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2490.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2490_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2489.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2489_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2476.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2476_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2502.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2502_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2516.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2516_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2517.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2517_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2503.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2503_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2477.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2477_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2488.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2488_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2475.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2475_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2515.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2515_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2501.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2501_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2500.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2500_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2514.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2514_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2510.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2510_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2504.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2504_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2505.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2505_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2511.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2511_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2498.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2498_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2507.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2507_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2513.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2513_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2512.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2512_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2506.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2506_angles.csv\n",
      "📽️ Processing: cricket_shot/Pull_Shot/IMG_2499.MOV\n",
      "✅ Saved: cricket_shot_angles/Pull_Shot/IMG_2499_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2583.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2583_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2568.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2568_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2569.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2569_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2582.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2582_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2594.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2594_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2580.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2580_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2581.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2581_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2595.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2595_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2591.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2591_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2585.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2585_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2584.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2584_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2590.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2590_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2586.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2586_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2592.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2592_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2579.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2579_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2578.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2578_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2593.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2593_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2587.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2587_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2575.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2575_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2574.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2574_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2589.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2589_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2576.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2576_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2563.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2563_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2577.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2577_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2588.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2588_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2573.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2573_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2567.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2567_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2566.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2566_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2572.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2572_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2564.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2564_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2570.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2570_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2571.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2571_angles.csv\n",
      "📽️ Processing: cricket_shot/Sweep_Shot/IMG_2565.MOV\n",
      "✅ Saved: cricket_shot_angles/Sweep_Shot/IMG_2565_angles.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "dataset_path = \"cricket_shot\"\n",
    "output_path = \"cricket_shot_angles\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# MediaPipe Pose setup\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Helper to calculate angle between 3 points\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    return 360 - angle if angle > 180 else angle\n",
    "\n",
    "# Helper to get landmark coordinates\n",
    "def get_lm(lm, name):\n",
    "    return [lm[mp_pose.PoseLandmark[name].value].x, lm[mp_pose.PoseLandmark[name].value].y]\n",
    "\n",
    "# Go through all subfolders and video files\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".mp4\", \".mov\")):\n",
    "            video_path = os.path.join(root, file)\n",
    "            print(f\"📽️ Processing: {video_path}\")\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            angles = []\n",
    "            frame_count = 0\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame = cv2.resize(frame, (640, 360))\n",
    "                results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                frame_count += 1\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    lm = results.pose_landmarks.landmark\n",
    "                    try:\n",
    "                        rs = get_lm(lm, \"RIGHT_SHOULDER\")\n",
    "                        re = get_lm(lm, \"RIGHT_ELBOW\")\n",
    "                        rw = get_lm(lm, \"RIGHT_WRIST\")\n",
    "                        rh = get_lm(lm, \"RIGHT_HIP\")\n",
    "                        rk = get_lm(lm, \"RIGHT_KNEE\")\n",
    "                        ra = get_lm(lm, \"RIGHT_ANKLE\")\n",
    "                        le = get_lm(lm, \"LEFT_EYE\")\n",
    "                        no = get_lm(lm, \"NOSE\")\n",
    "                        reye = get_lm(lm, \"RIGHT_EYE\")\n",
    "\n",
    "                        angles.append({\n",
    "                            \"frame\": frame_count,\n",
    "                            \"elbow\": calculate_angle(rs, re, rw),\n",
    "                            \"shoulder\": calculate_angle(rh, rs, re),\n",
    "                            \"knee\": calculate_angle(rh, rk, ra),\n",
    "                            \"body\": calculate_angle(rs, rh, rk),\n",
    "                            \"face\": calculate_angle(le, no, reye)\n",
    "                        })\n",
    "                    except:\n",
    "                        continue\n",
    "            cap.release()\n",
    "\n",
    "            # Save to proper subfolder\n",
    "            if angles:\n",
    "                shot_type = os.path.basename(root)  # e.g., Cover_Drive\n",
    "                base_name = os.path.splitext(file)[0]  # e.g., video1\n",
    "                save_dir = os.path.join(output_path, shot_type)\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f\"{base_name}_angles.csv\")\n",
    "                df = pd.DataFrame(angles)\n",
    "                df.to_csv(save_path, index=False)\n",
    "                print(f\"✅ Saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m68,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,189</span> (301.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,189\u001b[0m (301.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,189</span> (301.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,189\u001b[0m (301.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3003 - loss: 1.5635 - val_accuracy: 0.6190 - val_loss: 1.2952\n",
      "Epoch 2/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6580 - loss: 1.2460 - val_accuracy: 0.6905 - val_loss: 1.1391\n",
      "Epoch 3/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7348 - loss: 1.0839 - val_accuracy: 0.7381 - val_loss: 1.0327\n",
      "Epoch 4/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7165 - loss: 0.9921 - val_accuracy: 0.6667 - val_loss: 0.9455\n",
      "Epoch 5/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6778 - loss: 0.9550 - val_accuracy: 0.7857 - val_loss: 0.8440\n",
      "Epoch 6/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7197 - loss: 0.8245 - val_accuracy: 0.7381 - val_loss: 0.7701\n",
      "Epoch 7/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7520 - loss: 0.7105 - val_accuracy: 0.7857 - val_loss: 0.7358\n",
      "Epoch 8/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8058 - loss: 0.6018 - val_accuracy: 0.7857 - val_loss: 0.6373\n",
      "Epoch 9/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8136 - loss: 0.5952 - val_accuracy: 0.8333 - val_loss: 0.5940\n",
      "Epoch 10/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8636 - loss: 0.5131 - val_accuracy: 0.7143 - val_loss: 0.6711\n",
      "Epoch 11/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8250 - loss: 0.5454 - val_accuracy: 0.8095 - val_loss: 0.6169\n",
      "Epoch 12/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8880 - loss: 0.4753 - val_accuracy: 0.8095 - val_loss: 0.5912\n",
      "Epoch 13/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8734 - loss: 0.3719 - val_accuracy: 0.8095 - val_loss: 0.5051\n",
      "Epoch 14/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8995 - loss: 0.3766 - val_accuracy: 0.8571 - val_loss: 0.4859\n",
      "Epoch 15/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9064 - loss: 0.3376 - val_accuracy: 0.7857 - val_loss: 0.4841\n",
      "Epoch 16/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9644 - loss: 0.2665 - val_accuracy: 0.9048 - val_loss: 0.4597\n",
      "Epoch 17/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9552 - loss: 0.2651 - val_accuracy: 0.8810 - val_loss: 0.4211\n",
      "Epoch 18/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9508 - loss: 0.2285 - val_accuracy: 0.8571 - val_loss: 0.4119\n",
      "Epoch 19/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9490 - loss: 0.1961 - val_accuracy: 0.8333 - val_loss: 0.4026\n",
      "Epoch 20/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9719 - loss: 0.1597 - val_accuracy: 0.8571 - val_loss: 0.4313\n",
      "Epoch 21/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9749 - loss: 0.1418 - val_accuracy: 0.8810 - val_loss: 0.3839\n",
      "Epoch 22/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9817 - loss: 0.1271 - val_accuracy: 0.8810 - val_loss: 0.3584\n",
      "Epoch 23/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9626 - loss: 0.1359 - val_accuracy: 0.8810 - val_loss: 0.3518\n",
      "Epoch 24/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9941 - loss: 0.0915 - val_accuracy: 0.8810 - val_loss: 0.3590\n",
      "Epoch 25/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0889 - val_accuracy: 0.8571 - val_loss: 0.3632\n",
      "Epoch 26/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9933 - loss: 0.0748 - val_accuracy: 0.8810 - val_loss: 0.3706\n",
      "Epoch 27/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0528 - val_accuracy: 0.8571 - val_loss: 0.3581\n",
      "Epoch 28/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0541 - val_accuracy: 0.8571 - val_loss: 0.4228\n",
      "Epoch 29/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0458 - val_accuracy: 0.8571 - val_loss: 0.3622\n",
      "Epoch 30/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0363 - val_accuracy: 0.8571 - val_loss: 0.4287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM model and label encoder saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Paths\n",
    "data_folder = 'cricket_shot_angles'\n",
    "sequence_length = 60  # Max frames per video\n",
    "angle_features = ['elbow', 'shoulder', 'knee', 'body', 'face']\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "# Step 1: Read angle sequences and labels\n",
    "for shot_type in os.listdir(data_folder):\n",
    "    shot_path = os.path.join(data_folder, shot_type)\n",
    "    if not os.path.isdir(shot_path):\n",
    "        continue\n",
    "    for csv_file in os.listdir(shot_path):\n",
    "        if csv_file.endswith('.csv'):\n",
    "            file_path = os.path.join(shot_path, csv_file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if df.shape[0] < 5:\n",
    "                continue  # skip tiny files\n",
    "\n",
    "            # Step 2: Select angle columns and pad/truncate to 60 frames\n",
    "            angles_seq = df[angle_features].values\n",
    "            if angles_seq.shape[0] > sequence_length:\n",
    "                angles_seq = angles_seq[:sequence_length]\n",
    "            elif angles_seq.shape[0] < sequence_length:\n",
    "                pad = np.zeros((sequence_length - angles_seq.shape[0], len(angle_features)))\n",
    "                angles_seq = np.vstack([angles_seq, pad])\n",
    "\n",
    "            X.append(angles_seq)\n",
    "            y.append(shot_type)\n",
    "\n",
    "# Step 3: Convert to arrays\n",
    "X = np.array(X)  # shape: (num_samples, 60, 5)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Step 4: Train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: LSTM model\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0.0, input_shape=(sequence_length, len(angle_features))))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Step 6: Train\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=16)\n",
    "\n",
    "# Step 7: Save model and label encoder\n",
    "model.save(\"lstm_shot_classifier.h5\")\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"✅ LSTM model and label encoder saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Shot Type   Elbow  Shoulder    Knee    Body   Face\n",
      "0      Defence  119.50     28.02  120.82   95.43  84.11\n",
      "1     Cut_shot   90.33     69.92   92.65   90.49  54.96\n",
      "2  Cover_Drive  104.09     84.16  109.11  105.38  63.98\n",
      "3    Pull_Shot   85.16     66.60  127.58  129.05  53.78\n",
      "4   Sweep_Shot  117.42     50.02  104.57   99.62  68.40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path to your angle CSV folders\n",
    "angle_dir = \"cricket_shot_angles\"\n",
    "\n",
    "# To store cumulative values\n",
    "angle_sums = defaultdict(lambda: {'elbow': [], 'shoulder': [], 'knee': [], 'body': [], 'face': []})\n",
    "\n",
    "# Loop through each shot type folder\n",
    "for shot_type in os.listdir(angle_dir):\n",
    "    shot_folder = os.path.join(angle_dir, shot_type)\n",
    "    if not os.path.isdir(shot_folder):\n",
    "        continue\n",
    "\n",
    "    for csv_file in os.listdir(shot_folder):\n",
    "        if csv_file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(shot_folder, csv_file))\n",
    "            if len(df) == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute average for this video\n",
    "            avg_angles = df[['elbow', 'shoulder', 'knee', 'body', 'face']].mean()\n",
    "\n",
    "            # Append to shot type's angle list\n",
    "            for key in avg_angles.keys():\n",
    "                angle_sums[shot_type][key].append(avg_angles[key])\n",
    "\n",
    "# Create final average table\n",
    "summary_data = {\n",
    "    \"Shot Type\": [],\n",
    "    \"Elbow\": [],\n",
    "    \"Shoulder\": [],\n",
    "    \"Knee\": [],\n",
    "    \"Body\": [],\n",
    "    \"Face\": []\n",
    "}\n",
    "\n",
    "for shot_type, values in angle_sums.items():\n",
    "    summary_data[\"Shot Type\"].append(shot_type)\n",
    "    summary_data[\"Elbow\"].append(round(pd.Series(values[\"elbow\"]).mean(), 2))\n",
    "    summary_data[\"Shoulder\"].append(round(pd.Series(values[\"shoulder\"]).mean(), 2))\n",
    "    summary_data[\"Knee\"].append(round(pd.Series(values[\"knee\"]).mean(), 2))\n",
    "    summary_data[\"Body\"].append(round(pd.Series(values[\"body\"]).mean(), 2))\n",
    "    summary_data[\"Face\"].append(round(pd.Series(values[\"face\"]).mean(), 2))\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Save or display\n",
    "summary_df.to_csv(\"average_shot_angles.csv\", index=False)\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load model and label encoder\n",
    "model = load_model(\"lstm_shot_classifier.h5\")\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Define angle columns and sequence length\n",
    "angle_features = ['elbow', 'shoulder', 'knee', 'body', 'face']\n",
    "sequence_length = 60\n",
    "\n",
    "def predict_shot_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    angles_seq = df[angle_features].values\n",
    "\n",
    "    # Pad or truncate to fixed length\n",
    "    if angles_seq.shape[0] > sequence_length:\n",
    "        angles_seq = angles_seq[:sequence_length]\n",
    "    elif angles_seq.shape[0] < sequence_length:\n",
    "        pad = np.zeros((sequence_length - angles_seq.shape[0], len(angle_features)))\n",
    "        angles_seq = np.vstack([angles_seq, pad])\n",
    "\n",
    "    # Reshape for prediction: (1, 60, 5)\n",
    "    angles_seq = np.expand_dims(angles_seq, axis=0)\n",
    "    prediction = model.predict(angles_seq)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])[0]\n",
    "\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and Label Encoder loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "model = load_model(\"lstm_shot_classifier.h5\")\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "print(\"✅ Model and Label Encoder loaded successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
